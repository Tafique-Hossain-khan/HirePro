{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tafique Hossain\n",
      "[nltk_data]     Khan\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Resume 1 - Similarity Score: 0.53\n",
      "Rank 2: Resume 3 - Similarity Score: 0.51\n",
      "Rank 3: Resume 2 - Similarity Score: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Similarity Score: 0.11\n"
     ]
    }
   ],
   "source": [
    "# Sample resumes and job description\n",
    "import fitz\n",
    "doc = fitz.open(\"D:/final_year_project/Experiments/Junet-Aktar_Resume.pdf\", filetype=\"pdf\")\n",
    "\n",
    "resume = \"\\n\".join(page.get_text() for page in doc) \n",
    "\n",
    "job_description = \"\"\" \n",
    "                Job Title: Data Scientist | Machine Learning Engineer\n",
    "\n",
    "Location: Remote / Onsite / Hybrid\n",
    "Employment Type: Full-time\n",
    "\n",
    "Job Summary:\n",
    "We are looking for a Data Scientist | Machine Learning Engineer with hands-on experience in building end-to-end machine learning projects and deploying models using MLOps tools. The ideal candidate should have expertise in data preprocessing, feature engineering, model evaluation, and deployment. This role requires a strong foundation in machine learning, deep learning, and statistical analysis, along with experience in containerization and workflow automation.\n",
    "\n",
    "Key Responsibilities:\n",
    "Design and develop machine learning models for predictive analytics and recommendation systems.\n",
    "Implement ETL processes, feature engineering, and data preprocessing techniques.\n",
    "Deploy and monitor machine learning models using MLflow, DVC, and Docker.\n",
    "Automate model training pipelines using Apache Airflow and DAGsHub.\n",
    "Utilize NLP techniques (NLTK, SpaCy) for sentiment analysis and text-based predictions.\n",
    "Build interactive web applications for machine learning models using Streamlit.\n",
    "Conduct hypothesis testing and statistical validation to improve model accuracy.\n",
    "Work with SQL and MySQL for data retrieval and database management.\n",
    "Create data visualizations using Matplotlib, Seaborn, and Plotly for insights and reporting.\n",
    "Required Skills & Qualifications:\n",
    "Education: Bachelor of Technology (B.Tech) in Computer Science with a specialization in Data Science (CGPA 8.91).\n",
    "Programming Languages: Python, Java, SQL.\n",
    "Machine Learning Concepts: Supervised/Unsupervised Learning, Feature Engineering, Model Evaluation, Data Wrangling, Statistical Analysis.\n",
    "MLOps Tools: MLflow, DVC, Apache Airflow, DAGsHub, Docker, Git.\n",
    "Data Visualization Tools: Power BI, Matplotlib, Seaborn, Plotly.\n",
    "Libraries & Frameworks: Pandas, NumPy, Scikit-Learn, NLTK, SpaCy, Streamlit.\n",
    "Soft Skills: Problem-solving, critical thinking, attention to detail, and strong communication skills.\n",
    "Preferred Experience:\n",
    "Built and deployed food delivery time prediction models with automated pipelines.\n",
    "Developed a restaurant sentiment analysis & recommendation system using cosine similarity.\n",
    "Created a health prediction web app for diabetes and heart disease risk assessment, handling imbalanced datasets with SMOTE.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove links\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)  # Remove emails\n",
    "    text = re.sub(r'\\+?\\d[\\d -]{8,}\\d', '', text)  # Remove phone numbers\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])  # Remove stopwords \n",
    "    \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "# Apply preprocessing\n",
    "processed_resume = preprocess_text(resume)\n",
    "processed_jd = preprocess_text(job_description)\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([processed_resume, processed_jd])\n",
    "\n",
    "# Compute similarity\n",
    "similarity_score = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "\n",
    "# Display result\n",
    "print(f\"Resume Similarity Score: {similarity_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tafique hossain khan รณ r github profile linkedin profile profile summary data science student hands experience building machine learning projects using various libraries mlops tools proficient machine learning deep learning algorithms practical knowledge end end model deployment skilled applying data science techniques solve real world problems effectively education gandhi institute technological advancement bhubaneswar india bachelor technology cse specialization data science cgpa vyasanagar public school odisha india xii secondary education percentage vyasanagar public school odisha india x primary education percentage technical skills languages python java mysql concepts machine learning algorithms statistical analysis etl process feature engineering model evaluation data wrangling data cleaning mathematics machine learning deep learning tools docker git dvc mlflow apache airflow dagshub power bi libraries pandas numpy scikit learn sklearn matplotlib seaborn plotly nltk spacy streamlit projects food delivery time prediction employed feature extraction techniques enhance model accuracy utilizing dvc data versioning integrating mlflow dagshub streamlined experiment tracking model registration developed automated training pipeline apache airflow containerized application using docker leveraging registered mlflow model accurate delivery time predictions restaurant sentiment analysis recommendation system developed web app analyzes reviews using nlp sentiment analysis personalized restaurant recommendations used cosine similarity content based recommendation system filtering recommendation system based cuisine ratings validated sentiment analysis results hypothesis testing creating user friendly interface streamlit health prediction web app developed health condition prediction web app diabetes heart disease risk assessments using machine learning early health insights implemented symptom based predictions handled imbalanced datasets techniques like smote enhance prediction accuracy built python streamlit creating interactive user friendly experience personalized health assessments certifications data science masters platform pw skills certificate id cdb af fbd completion time february view certificate\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_text(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
